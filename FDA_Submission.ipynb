{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA  Submission\n",
    "\n",
    "**Your Name:** Dieter Verbeemen\n",
    "\n",
    "**Name of your Device:** The Chest X-Rays Pneumonia Notifier\n",
    "\n",
    "## Algorithm Description\n",
    "\n",
    "### 1. General Information\n",
    "\n",
    "**Intended Use Statement:**\n",
    "Notify (help) radiologist detect pneumonia\n",
    "\n",
    "**Indications for Use:**\n",
    "- The image must be a X-ray\n",
    "- The X-ray image must be a DICOM file\n",
    "- The X-ray image must be taken from the chest\n",
    "- The X-ray image must be taken in the AP or PA position\n",
    "- The patient, man or women should be between 1 and 90 years old\n",
    "\n",
    "\n",
    "**Device Limitations:**\n",
    "- Any modern computer with a standard CPU, although a GPU is advised\n",
    "\n",
    "**Clinical Impact of Performance:**\n",
    "- The best use for this model is to prioritize the worklist.\n",
    "- The model has a low precision and a higher recall.\n",
    "  - (Recall) This means if we have 100 patients with pneumonia,  \n",
    "Then we can properly classify these 100 patients as a positive event.  \n",
    "(without classifying them too much as _no pneumonia_).\n",
    "  - Unfortunately, the precision is not very high. This means that  \n",
    "we will also classify healthy patients as pneumonia.\n",
    " - However, if we want to prioritize our worklist then we should prioritize our ill patients above  \n",
    "   the healthy patients (recall). But it isn't harmful to classify a healthy person with pneumonia.\n",
    "\n",
    "### 2. Algorithm Design and Function\n",
    "\n",
    "<img src=\"./images/model_workflow.png\" />\n",
    "\n",
    "**DICOM Checking Steps:**\n",
    "- Modality must be \"DX\"\n",
    "- Body part examined must be \"CHEST\"\n",
    "- Patient Position must be \"PA\" or \"AP\"\n",
    "\n",
    "**Preprocessing Steps:**\n",
    "- Image is normalized between 0 and 1\n",
    "- Image is reshaped to a 224 x 224 image\n",
    "- Image is repeated across 3 channels\n",
    "\n",
    "**CNN Architecture:**\n",
    "\n",
    "```python\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "model (Model)                (None, 7, 7, 512)         14714688  \n",
    "_________________________________________________________________\n",
    "flatten (Flatten)            (None, 25088)             0         \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 25088)             0         \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 1024)              25691136  \n",
    "_________________________________________________________________\n",
    "dropout_1 (Dropout)          (None, 1024)              0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 512)               524800    \n",
    "_________________________________________________________________\n",
    "dropout_2 (Dropout)          (None, 512)               0         \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 256)               131328    \n",
    "_________________________________________________________________\n",
    "dropout_3 (Dropout)          (None, 256)               0         \n",
    "_________________________________________________________________\n",
    "dense_3 (Dense)              (None, 1)                 257       \n",
    "=================================================================\n",
    "Total params: 41,062,209\n",
    "Trainable params: 28,707,329\n",
    "Non-trainable params: 12,354,880\n",
    "_________________________________________________________________\n",
    "```\n",
    "\n",
    "*Model info:*\n",
    "- The model contains out of 2 parts:\n",
    " - Part 1) A pre-trained [VGG16 model](https://keras.io/api/applications/vgg/):\n",
    "    - A 16 layer pre-trained convolutional neural network based on imagenet.  \n",
    "      The weights are not trainable.\n",
    " - Part 2) Four dense layers, each with its own dropout layer\n",
    "\n",
    "### 3. Algorithm Training\n",
    "\n",
    "**Parameters:**\n",
    "* Types of augmentation used during training  \n",
    "    - Rescale: pixel_value / 255\n",
    "    - Horizontal flips: True,\n",
    "    - Vertical flip: False,\n",
    "    - Height shift range: 0.1,\n",
    "    - Width shift range: 0.1,\n",
    "    - Rotation range: 20,\n",
    "    - Shear range: 0.1,\n",
    "    - Zoom range: 0.1\n",
    "    \n",
    "    \n",
    "-  Batch size: 64   \n",
    "- Optimizer: Adam    \n",
    "- Optimizer learning rate: 0.0003    \n",
    "- Layers of pre-existing architecture that were frozen: First 16 layers of a VGG model  \n",
    "- Layers of pre-existing architecture that were fine-tuned: None  \n",
    "- Layers added to pre-existing architecture: Flatten, Dense and Dropout layers  \n",
    "\n",
    "<img src=\"./images/model_loss_accuracy.png\" />\n",
    "\n",
    "<img src=\"./images/model_recall_curve.png\" />\n",
    "\n",
    "<img src=\"./images/model_roc_curve.png\" />\n",
    "\n",
    "\n",
    "**Final Threshold and Explanation:**\n",
    "\n",
    "* Threshold: 0.37415\n",
    "* F1 Score: 0.46824\n",
    "\n",
    "The final threshold of 0.37415 was based on the highest F1-Score of 0.46824.\n",
    "Based on [this paper: CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning](https://arxiv.org/pdf/1711.05225.pdf),   \n",
    "the average radiologist had a F1 Score of 0.387. This means that our model achieved a better F-1 score than the average radiologist. _(Please note that we have no information about who these radiologists were and whether they are representative of all radiologists..)_\n",
    "\n",
    "\n",
    "### 4. Databases\n",
    "* Dataset: [NIH Chest X-ray Dataset](https://www.kaggle.com/nih-chest-xrays/data)\n",
    "* Amount of Chest, X-ray images: 112.120\n",
    "* Meta data:\n",
    " * Image Index\n",
    " * Finding Labels\n",
    " * Follow-up \n",
    " * Patient ID\n",
    " * Patient Age\n",
    " * Patient Gender\n",
    " * View Position\n",
    " * Original Image Size\n",
    " * Original Image Pixel Spacing  \n",
    " \n",
    "   \n",
    "* Amount of images with Pneumonia: 1431 (1.28%)  \n",
    "* Amount of images without Pneumonia: 110689 (98.72%)\n",
    "\n",
    "\n",
    "**Description of Training Dataset:**  \n",
    "1145 images (80%) which contained Pneumonia will be used in the training dataset.\n",
    "* Amount of Chest, X-ray images: 2290\n",
    " * Images containing pneumonia: 1145 (50%)\n",
    " * Images without pneumonia: 1145 (50%)\n",
    "\n",
    "**Description of Validation Dataset:**\n",
    "The remaining 286 images (20%) which contained Pneumonia will be used in the validation dataset.\n",
    " * Images containing pneumonia: 286 (25%)\n",
    " * Images without pneumonia: 858 (75%)\n",
    "\n",
    "### 5. Ground Truth\n",
    "* ChestX-ray dataset comprises 112,120 frontal-view X-ray images of 30,805 unique patients with the text-mined fourteen disease image labels (where each image can have multilabels)\n",
    "* The disease labels were created using Natural Language Processing (NLP) to mine the associated radiological reports\n",
    "* The labels are expected to be >90% accurate and suitable for weakly-supervised learning\n",
    "* The data includes 14 common thoracic pathologies:\n",
    "\t* Atelectasis\n",
    "\t* Consolidation\n",
    "\t* Infiltration\n",
    "\t* Pneumothorax\n",
    "\t* Edema\n",
    "\t* Emphysema\n",
    "\t* Fibrosis\n",
    "\t* Effusion\n",
    "\t* Pneumonia\n",
    "\t* Pleural thickening\n",
    "\t* Cardiomegaly\n",
    "\t* Nodule\n",
    "\t* Mass\n",
    "\t* Hernia\n",
    "\n",
    "_For more info: [https://www.kaggle.com/nih-chest-xrays/data](https://www.kaggle.com/nih-chest-xrays/data)_\n",
    "\n",
    "### 6. FDA Validation Plan\n",
    "\n",
    "**Patient Population Description for FDA Validation Dataset:**\n",
    "- The patient can be men or women\n",
    "- The recommended age is between 1 and 90 years old\n",
    "- Chest X-Ray image must be taken in the AP or PA position\n",
    "- Chest X-Ray image must be in DICOM format\n",
    "\n",
    "**Ground Truth Acquisition Methodology:**\n",
    "- Silver Standard: Validation by 4 different radiologists\n",
    "\n",
    "**Algorithm Performance Standard:**\n",
    "- The algorithmâ€™s F1 score should be more than that of average radiologist (0.387)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
